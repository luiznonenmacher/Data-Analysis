{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Storm Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will the storm_data from [here](https://dq-content.s3.amazonaws.com/251/storm_data.csv), a csv that simulates hurricane data. The csv contains the following fields:\n",
    "\n",
    "- fid - ID for the row\n",
    "- year - Recorded year\n",
    "- month - Recorded month\n",
    "- day - Recorded date\n",
    "- ad_time - Recorded time in UTC\n",
    "- btid - Hurricane ID\n",
    "- name - Name of the hurricane\n",
    "- lat - Latitude of the recorded location\n",
    "- long - Longitude of the recorded location\n",
    "- wind_kts - Wind speed in knots per second\n",
    "- pressure - Atmospheric pressure of the hurricane\n",
    "- cat - Hurricane category\n",
    "- basin - The basin the hurricane is located\n",
    "- shape_leng - Hurricane shape length\n",
    "\n",
    "The objective of the project is to take this data and add into a database. To create the database, we will use a local version of PostgreSQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ï»¿FID', 'YEAR', 'MONTH', 'DAY', 'AD_TIME', 'BTID', 'NAME', 'LAT', 'LONG', 'WIND_KTS', 'PRESSURE', 'CAT', 'BASIN', 'Shape_Leng']\n",
      "['2001', '1957', '8', '8', '1800Z', '63', 'NOTNAMED', '22.5', '-140', '50', '0', 'TS', 'Eastern Pacific', '1.140175']\n",
      "['2002', '1961', '10', '3', '1200Z', '116', 'PAULINE', '22.1', '-140.2', '45', '0', 'TS', 'Eastern Pacific', '1.16619']\n",
      "['2003', '1962', '8', '29', '0600Z', '124', 'C', '18', '-140', '45', '0', 'TS', 'Eastern Pacific', '2.10238']\n",
      "['2004', '1967', '7', '14', '0600Z', '168', 'DENISE', '16.6', '-139.5', '45', '0', 'TS', 'Eastern Pacific', '2.12132']\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from urllib import request\n",
    "import csv\n",
    "import psycopg2\n",
    "\n",
    "response = request.urlopen('https://dq-content.s3.amazonaws.com/251/storm_data.csv')\n",
    "reader = csv.reader(io.TextIOWrapper(response))\n",
    "\n",
    "line_number = 0\n",
    "for line in reader:\n",
    "    if line_number < 5:\n",
    "        print(line)\n",
    "        line_number +=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"postgres\", user=\"postgres\", password=\"upsdflintmobile\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "query1 = \"DROP TABLE IF EXISTS storm\"\n",
    "query2 =\"\"\"CREATE TABLE storm(\n",
    "id INTEGER PRIMARY KEY,\n",
    "date TIMESTAMP,\n",
    "btid INTEGER,\n",
    "name VARCHAR(15),\n",
    "latitude DECIMAL(4,1),\n",
    "longitude DECIMAL(4,1),\n",
    "wind_kts INTEGER,\n",
    "pressure INTEGER,\n",
    "cat VARCHAR(3),\n",
    "basin VARCHAR(16),\n",
    "shape_leng DECIMAL(8,6)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(query1)\n",
    "cur.execute(query2)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating users and giving permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create two users: a data_production, that can insert, update and read the data but not delete it and a data_analyst, that can only run queries to read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"postgres\", user=\"postgres\", password=\"upsdflintmobile\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"CREATE USER data_production WITH NOSUPERUSER PASSWORD 'production'\"\"\")\n",
    "cur.execute('REVOKE ALL ON storm FROM data_production')\n",
    "cur.execute('GRANT SELECT, INSERT, UPDATE ON storm TO data_production')\n",
    "\n",
    "cur.execute(\"\"\"CREATE USER data_analyst WITH NOSUPERUSER PASSWORD 'analyst'\"\"\")\n",
    "cur.execute('REVOKE ALL ON storm FROM data_analyst')\n",
    "cur.execute('GRANT SELECT ON storm TO data_analyst')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read the csv into Pandas, so we can transform the YEAR, MONTH, DAY and AD_TIME columns into a timestamp. Then we export it into a csv and import the data into the database.\n",
    "\n",
    "Finally, we select the first line of the database as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://dq-content.s3.amazonaws.com/251/storm_data.csv')\n",
    "df['HOUR'] = df['AD_TIME'].map(lambda x: str(x)[0:2])\n",
    "df['MINUTE'] = df['AD_TIME'].map(lambda x: str(x)[2:4])\n",
    "df['DATE'] = pd.to_datetime(df[['DAY','MONTH','YEAR', 'HOUR', 'MINUTE']]\n",
    "                   .astype(str).apply(' '.join, 1), format='%d %m %Y %H %M')\n",
    "df.drop(['YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE', 'AD_TIME'], axis=1, inplace=True)\n",
    "df = df[['FID', 'DATE', 'BTID', 'NAME', 'LAT', 'LONG', 'WIND_KTS', 'PRESSURE', 'CAT','BASIN', 'Shape_Leng']]\n",
    "df.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"postgres\", user=\"postgres\", password=\"upsdflintmobile\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "with open('processed_data.csv', 'r') as f:\n",
    "    cur.copy_expert('COPY storm FROM STDIN WITH CSV HEADER', f)\n",
    "\n",
    "    conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001,\n",
       " datetime.datetime(1957, 8, 8, 18, 0),\n",
       " 63,\n",
       " 'NOTNAMED',\n",
       " Decimal('22.5'),\n",
       " Decimal('-140.0'),\n",
       " 50,\n",
       " 0,\n",
       " 'TS',\n",
       " 'Eastern Pacific',\n",
       " Decimal('1.140175'))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = psycopg2.connect(dbname=\"postgres\", user=\"postgres\", password=\"upsdflintmobile\")\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT * FROM storm')\n",
    "results = cur.fetchone()\n",
    "conn.close()\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
